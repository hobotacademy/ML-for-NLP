# Machine Learning for NLP üìù

Welcome to the official repository for **Machine Learning for Natural Language Processing** by **Hobot Academy**. This course serves as the bridge between classical Machine Learning algorithms and textual data analysis.

<div align="center">
  <img src="https://img.shields.io/badge/Instructor-Zahra%20Amini-blue?style=for-the-badge" alt="Instructor">
  <img src="https://img.shields.io/badge/Academy-Hobot%20Academy-red?style=for-the-badge" alt="Academy">
  <img src="https://img.shields.io/badge/Focus-Classical%20NLP-green?style=for-the-badge" alt="Focus">
</div>

---

## üåâ Bridging ML and Text
Before the era of Transformers (BERT, GPT), NLP relied heavily on statistical machine learning. This repository explores that foundational era. We focus on transforming unstructured text into structured numerical vectors and applying robust algorithms like SVM, Naive Bayes, and Logistic Regression to solve real-world language problems.

This is the **essential prerequisite** module before diving into Deep Learning for NLP.

---

## üõ†Ô∏è Curriculum & Roadmap

The repository is structured to mimic a standard NLP pipeline: **Preprocessing $\rightarrow$ Vectorization $\rightarrow$ Modeling**.

### Module 1: Text Wrangling & Vectorization
* **S00: Text_Preprocessing**
  * RegEx
* **S01 & S02: Text Preprocessing**
  * Tokenization, Stemming vs. Lemmatization, Stop-word removal, and cleaning pipelines using `NLTK` and `Spacy`.
* **S03 & S04: Feature Extraction**
  * Converting text to numbers: **Bag of Words (BoW)**, **TF-IDF**, and N-Grams. Understanding sparsity in text data.

### Module 2: Probabilistic & Geometric Models
* **S05 & S06: Intro to ML for Text**
  * Setting up the training pipeline for textual data.
* **S07 & S08: Logistic Regression**
  * Binary text classification and understanding decision boundaries in high-dimensional sparse data.
* **S09 & S10: KNN & Naive Bayes**
  * **K-Nearest Neighbors:** Distance-based classification for text.
  * **Naive Bayes:** Implementing the probabilistic approach (Multinomial & Bernoulli) which is the baseline for text classification.

### Module 3: Advanced Discriminative Models
* **S11 & S12: SVM & LDA**
  * **Support Vector Machines (SVM):** finding the optimal hyperplane for text categorization.
  * **Linear Discriminant Analysis (LDA):** Dimensionality reduction and class separation.

### Module 4: The Neural Shift
* **S13 & S14: Neural Networks & MLP**
  * Introduction to **Multi-Layer Perceptrons (MLP)** for text. Transitioning from statistical methods to connectionist models (Deep Learning).

---

## üíª Tech Stack
* **Language:** Python 3.x
* **NLP Libraries:** NLTK, Spacy, Re (Regular Expressions)
* **ML Core:** Scikit-Learn (sklearn)
* **Data Manipulation:** Pandas, NumPy

---

## üë©‚Äçüè´ About the Instructor: Zahra Amini

<img src="https://raw.githubusercontent.com/FortAwesome/Font-Awesome/6.x/svgs/brands/github.svg" width="30" alt="GitHub Logo"> [GitHub](https://github.com/aminizahra)

<img src="https://raw.githubusercontent.com/FortAwesome/Font-Awesome/6.x/svgs/solid/globe.svg" width="30" alt="Portfolio Logo"> [Portfolio](https://aminizahra.github.io/)

<img src="https://raw.githubusercontent.com/FortAwesome/Font-Awesome/6.x/svgs/brands/linkedin.svg" width="30" alt="LinkedIn Logo"> [LinkedIn](https://www.linkedin.com/in/zahraamini-ai/)
