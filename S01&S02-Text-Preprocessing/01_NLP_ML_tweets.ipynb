{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "992e1138-1a54-4a79-88ea-67e06c85e401",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Machine Learning for NLP</h1>\n",
    "    <h2 align=\"center\">Text Preprocessing</h2>\n",
    "    <h3 align=\"center\">Zahra Amini</h3>\n",
    "<div style=\"width: 100%; text-align: center;\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <a class=\"link\" href=\"https://t.me/Zahraamini_ai\">Telegram</a><br>\n",
    "                <a class=\"link\" href=\"https://www.linkedin.com/in/zahraamini-ai/\">LinkedIn</a><br>\n",
    "                <a class=\"link\" href=\"https://www.youtube.com/@AcademyHobot\">YouTube</a><br>\n",
    "            </td>\n",
    "            <td>\n",
    "                <a class=\"link\" href=\"https://github.com/aminizahra\">GitHub</a><br>\n",
    "                <a class=\"link\" href=\"https://www.kaggle.com/aminizahra\">Kaggle</a><br>\n",
    "                <a class=\"link\" href=\"https://www.instagram.com/zahraamini_ai/\">Instagram</a><br>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a68f927-1676-4c11-8c4a-9ccb0632fd74",
   "metadata": {},
   "source": [
    "## 1. Importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43180b61-af9d-4a33-a9e3-20beee2fe601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f7f31d-ad3b-4b8b-9551-3a7789905957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23309765-83b2-4758-ad09-c3c5749132ff",
   "metadata": {},
   "source": [
    "## 2. Download NLTK stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820b6447-7dd7-44ba-b941-496781ac1a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffe9bb-95aa-441c-a3bb-5e8fe6ab7f97",
   "metadata": {},
   "source": [
    "## 3. Initialize stopwords and the Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce9b472-017c-462c-ad46-e279c6153a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07824c83-bd7b-4a30-8d69-5248d52f43e5",
   "metadata": {},
   "source": [
    "## 4. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64111304-b23f-4839-9c1e-ddd3cb0ac11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'twitter_training.csv'\n",
    "data = pd.read_csv(file_path, header=None, names=['ID', 'Category', 'Sentiment', 'Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb4834-97ca-4fb3-9251-08bc697b5bf7",
   "metadata": {},
   "source": [
    "# 5. Define preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d652c841-f0f6-4a44-abe6-a448415ce136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_nltk(text):\n",
    "    # Check if text is not a string; if not, set it to an empty string\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    \n",
    "    # Remove usernames and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)   # Removes punctuation\n",
    "    text = re.sub(r'\\d+', '', text)       # Removes numbers\n",
    "    \n",
    "    # Tokenize, remove stopwords, and apply stemming\n",
    "    tokens = text.split()  # Split text into words\n",
    "    tokens = [ps.stem(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b254ad1-bef0-4519-832d-83ee7a6f5473",
   "metadata": {},
   "source": [
    "## 6. Apply preprocessing to the 'Text' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68e2a2c9-d5ae-4218-aef0-445ffed6ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Clean_Text'] = data['Text'].apply(preprocess_text_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfd5841e-203f-4754-9c98-95b0ca46447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment                 Clean_Text\n",
      "0  Positive   im get borderland murder\n",
      "1  Positive           come border kill\n",
      "2  Positive     im get borderland kill\n",
      "3  Positive  im come borderland murder\n",
      "4  Positive   im get borderland murder\n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned data\n",
    "print(data[['Sentiment', 'Clean_Text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b921fb-7bc2-416c-a694-932f7a5a0159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
